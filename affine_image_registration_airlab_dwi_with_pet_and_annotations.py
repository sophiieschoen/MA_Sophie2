# -*- coding: utf-8 -*-
"""Affine Image Registration Airlab DWI with PET and Annotations.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xrsaJzjYNuvXC45IxDcTzNy0AUIpvc0V
"""

from platform import python_version
python_version()

# Commented out IPython magic to ensure Python compatibility.
# download airlab
!git clone https://github.com/airlab-unibas/airlab.git
# %cd airlab

! pip install SimpleITK

! pip install neurite

!pip install torch

import SimpleITK as sitk
import numpy as np
import torch
import matplotlib.pyplot as plt
import airlab as al

import cv2

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive')
# %cd /gdrive

!ls '/gdrive/My Drive/DWI_Images/Originals'

!ls '/gdrive/My Drive/DWI_Images/Annotated'

!ls '/gdrive/My Drive/PET_Images'

def display_images(image, window_min=None, window_max=None, title=None):
    """
    Display one or more images
    image:  list of images or single image. image can be SimpleITK image, numpy array or torch tensor
    window_min: 
    window_max: 
    title: title for each image.
    """
    _

    N = len(image) if isinstance(image, list) else 1
    fig, ax = plt.subplots(1, N, figsize=(15, 6))

    if not isinstance(image, list): # plot one image
        display_images_single(ax, image, window_max=window_max, window_min=window_min, title=title)

    else: # plot multiple images
        if title is not None:
            assert len(title) == len(image)

        for n in range(N):
            display_images_single(ax[n], image[n], window_max=window_max, window_min=window_min, title=title[n] if title is not None else None)



def display_images_single(ax, image, window_min=0, window_max=255, title=None):

    if isinstance(image, sitk.SimpleITK.Image):
        img_np = sitk.GetArrayViewFromImage(image)
        if len(img_np.shape)==3:
            axis=img_np.shape[1]//2
            img_np = img_np[:,:,axis] #gets first slice of 3Dimage
    elif torch.is_tensor(image):
        img_np = image.numpy()
        # img_np = image.permute(1,0)
    elif type(image) is np.ndarray:
        img_np = image#np.transpose(image, (1,0))
    else:
        print("Wrong image format.")
        return

    if window_min is None:
        window_min = int(np.amin(img_np))
        # window_min = int(torch.min(img_np))
    if window_max is None:
        window_max = int(np.amax(img_np))
        # window_max = int(torch.max(img_np))
    
    # We assume the original slice is isotropic, otherwise the display would be distorted
    ax.imshow(img_np, cmap='gray', vmin=window_min, vmax=window_max)
    # ax[n].axis('off')
    if title is not None:
        ax.set_title(title)


def plot_warped_grid(ax, disp, bg_img=None, interval=3, title="Deformation", fontsize=30, color='c'):
    """disp shape (2, H, W)
    
      source: https://github.com/qiuhuaqi/midir
    """
    if bg_img is not None:
        background = bg_img
    else:
        background = np.zeros(disp.shape[1:])

    id_grid_H, id_grid_W = np.meshgrid(range(0, background.shape[0] - 1, interval),
                                       range(0, background.shape[1] - 1, interval),
                                       indexing='ij')

    new_grid_H = id_grid_H + disp[0, id_grid_H, id_grid_W]
    new_grid_W = id_grid_W + disp[1, id_grid_H, id_grid_W]

    kwargs = {"linewidth": 1.5, "color": color}
    # matplotlib.plot() uses CV x-y indexing
    for i in range(new_grid_H.shape[0]):
        ax.plot(new_grid_W[i, :], new_grid_H[i, :], **kwargs)  # each draws a horizontal line
    for i in range(new_grid_H.shape[1]):
        ax.plot(new_grid_W[:, i], new_grid_H[:, i], **kwargs)  # each draws a vertical line

    ax.set_title(title, fontsize=fontsize)
    ax.imshow(background, cmap='gray')
    # ax.axis('off')
    ax.grid(False)
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_frame_on(False)

def resample(img, reference=None, new_size=None, new_spacing=None, transform=None, downsample=0, interp='linear'):
    """
    Resample an ITK image to either:
    a reference image given by an ITK image or,
    a desired voxel spacing in mm given by [spXmm, spYmm, spZmm] or,
    a desired size [x, y, z], or
    a downsampling factor (applied to the voxel spacing)

    Arguments
    ---------
    `reference` : ITK image
    `downsample` : scalar
    `out_spacing` : tuple or list (e.g [1.,1.,1.])
        New spacing in mm.
    `out_size` : tuple or list of ints (e.g. [100, 100, 100])
    `interp` : string or list/tuple of string
        possible values from this set: {'linear', 'nearest', 'bspline'}
        Different types of interpolation can be provided for each input,
        e.g. for two inputs, `interp=['linear','nearest']
    `transform`: spatial tranform

    """
    in_size = img.GetSize()
    in_spacing = img.GetSpacing()
    new_origin = img.GetOrigin()
    dim = img.GetDimension()
    
    if not downsample:
        if reference is not None:
            new_spacing = reference.GetSpacing()
            new_size = reference.GetSize()
            new_origin = reference.GetOrigin()
        
        else:
            # if new_size is None and new_spacing is None:
                # return img
    
            if new_size is None and new_spacing is not None:
                # Compute new image dimensions based on the desired rescaling of the voxel spacing
                new_size = [int(np.ceil(in_size[d] * in_spacing[d] / new_spacing[d])) for d in range(dim)]

            if new_spacing is None and new_size is not None:
                # Compute new voxel spacing based on the desired rescaling of the image dimensions
                new_spacing = [in_spacing[d] * in_size[d] / new_size[d] for d in range(dim)]
    else:
        new_spacing = [in_spacing[d] * downsample for d in range(dim)]
        new_size = [int(np.ceil(in_size[d] * in_spacing[d] / new_spacing[d])) for d in range(dim)]

    if new_spacing is None:
        new_spacing = in_spacing
    if new_size is None:
        new_size = in_size

    if transform is None:
        transform = sitk.Transform()

    if interp == 'linear':
        interp_func = sitk.sitkLinear
    elif interp == 'nearest':
        interp_func = sitk.sitkNearestNeighbor
    elif interp == 'bspline':
        interp_func = sitk.sitkBSpline

    # Smooth the input image with anisotropic Gaussian filter
    img_smoothed = img
    for d in range(dim):
        # Note how the blurring strength can be different in each direction,
        # if the scaling factors are different.
        factor = new_spacing[d] / in_spacing[d]
        sigma = 0.2 * factor
        img_smoothed = sitk.RecursiveGaussian(img_smoothed, sigma=sigma, direction=d)

    # Finally, apply the resampling operation
    # img_resampled = sitk.ResampleImageFilter().Execute(
    img_resampled = sitk.Resample(
        img_smoothed,  # Input image
        new_size,            # Output image dimensions
        transform,           # Coordinate transformation. sitk.Transform() is a dummy identity transform,
                             # as we want the brain to be in exactly the same place. When we do image registration,
                             # for example, this can be a linear or nonlinear transformation.
        interp_func,     # Interpolation method (cf. also sitk.sitkNearestNeighbor and many others)
        new_origin,     # Output image origin (same)
        new_spacing,         # Output voxel spacing
        img.GetDirection(),  # Output image orientation (same)
        0,                   # Fill value for points outside the input domain
        img.GetPixelID())    # Voxel data type (same)

    return img_resampled

def image_to_itk(in_image, direction=None):
    """
        Convert airlab image to sitk image.
        Reimplements .itk() of the airlab image with correctly premutation of axis (x- and z-axis)
    """

    image = al.utils.Image(in_image.image.cpu().clone(), in_image.size, in_image.spacing, in_image.origin)
    # image._reverse_axis()
    image.image.squeeze_()

    itk_image = sitk.GetImageFromArray(image.image.numpy())

    spacing = []
    origin = []
    for d in range(len(in_image.spacing)):
        if isinstance(in_image.spacing[d], torch.Tensor):
            spacing.append(in_image.spacing[d].item())
        else:
            spacing.append(in_image.spacing[d])
        if isinstance(in_image.origin[d], torch.Tensor):
            origin.append(in_image.origin[d].item())
        else:
            origin.append(in_image.origin[d])

    itk_image.SetSpacing(spacing=spacing)
    itk_image.SetOrigin(origin=origin)
    if direction is not None:
        itk_image.SetDirection(direction)
        
    return itk_image

## IMAGE REGISTRATION OF ANNOTATED IMAGES ##

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

fixed = sitk.ReadImage('/gdrive/My Drive/DWI_Images/Originals/N10-DWI-800.nii.gz')
moving = sitk.ReadImage('/gdrive/My Drive/PET_Images/N10_SUV.nii.gz')
annotated=sitk.ReadImage('/gdrive/My Drive/DWI_Images/Annotated/N10.nii.gz')

#display_images([image_to_itk(fixed_image), image_to_itk(moving_image)],
 #   title=['Fixed image', 'Moving image before'], window_max=1, window_min=0)
print("MOVING IMAGE")
print("image spacing: {}".format(moving.GetSpacing()))
print("image origin: {}".format(moving.GetOrigin()))
print("image size: {}".format(moving.GetSize()))

print("ANNOTATED IMAGE")
print("image spacing: {}".format(annotated.GetSpacing()))
print("image origin: {}".format(annotated.GetOrigin()))
print("image size: {}".format(annotated.GetSize()))

print("FIXED IMAGE")
print("image spacing: {}".format(fixed.GetSpacing()))
print("image origin: {}".format(fixed.GetOrigin()))
print("image size: {}".format(fixed.GetSize()))

#give moving image same size and spacing than fixed one:
movingres = sitk.Resample(moving, fixed, sitk.Transform(), sitk.sitkLinear,0, moving.GetPixelID())
annotatedres=sitk.Resample(annotated, fixed, sitk.Transform(), sitk.sitkLinear,0, moving.GetPixelID())

print("MOVING IMAGE RESAMPLED")
print("image spacing: {}".format(movingres.GetSpacing()))
print("image origin: {}".format(movingres.GetOrigin()))
print("image size: {}".format(movingres.GetSize()))

print("ANNOTATED IMAGE RESAMPLED")
print("image spacing: {}".format(annotatedres.GetSpacing()))
print("image origin: {}".format(annotatedres.GetOrigin()))
print("image size: {}".format(annotatedres.GetSize()))

#annotation and original should have same orientation: 
#sitk.GetDierection()
print("image direction BEFORE")
print("image direction fixed: {}".format(fixed.GetDirection()))
print("image direction moving: {}".format(movingres.GetDirection()))
print("image direction annotated: {}".format(annotatedres.GetDirection()))

#to give them the same orientation
fixed = sitk.DICOMOrient(fixed, 'LPS') #LPS=new orientation  (or RAI)
annotatedres = sitk.DICOMOrient(annotatedres, 'LPS')
movingres = sitk.DICOMOrient(movingres, 'LPS')

print("image direction AFTER REDIRECTION")
print("image direction fixed: {}".format(fixed.GetDirection()))
print("image direction moving: {}".format(movingres.GetDirection()))
print("image direction annotated: {}".format(annotatedres.GetDirection()))

#sitk.WriteImage(annotatedres, '/gdrive/My Drive/DWI_Images/resampled_annotationpatient47_itk.nii.gz')

#print(movingres.dtype)
#print(fixed.dtype)


'''
#convert sitk to numpy array:
movingres_np = sitk.GetArrayFromImage(movingres)
print(movingres_np.dtype)

#change type of ndarray:
movingres_np_float32=movingres_np.astype('float32')
print(movingres_np_float32.dtype)
print(type(movingres_np_float32))

#convert back to itk image:
movingres_itk_float32 =sitk.GetImageFromArray(movingres_np_float32)
print(type(movingres_itk_float32))
'''

'''
#check if they have the same origin, direction, spacing etc.
print("image direction: {}".format(movingres.GetDirection())) 
print("image origin: {}".format(movingres.GetOrigin()))
print("image size: {}".format(movingres.GetSize()))
print("image spacing: {}".format(movingres.GetSpacing()))

print("image direction: {}".format(fixed.GetDirection())) 
print("image origin: {}".format(fixed.GetOrigin()))
print("image size: {}".format(fixed.GetSize()))
print("image spacing: {}".format(fixed.GetSpacing()))
'''
'''
#check values before change:
print("image direction: {}".format(movingres_itk_float32.GetDirection())) 
print("image origin: {}".format(movingres_itk_float32.GetOrigin()))
print("image size: {}".format(movingres_itk_float32.GetSize()))
print("image size: {}".format(movingres_itk_float32.GetSpacing()))


print("image direction: {}".format(fixed.GetDirection())) 
fixedDirection=fixed.GetDirection()
print("image origin: {}".format(fixed.GetOrigin()))
fixedOrigin=fixed.GetOrigin()
print("image size: {}".format(fixed.GetSize()))
fixedSize=fixed.GetSize()
print("image size: {}".format(fixed.GetSpacing()))
fixedSpacing=fixed.GetSpacing()

# set Origin and direction to moving image
movingres_itk_float32.SetOrigin(fixedOrigin)
movingres_itk_float32.SetSpacing(fixedSpacing)
movingres_itk_float32.SetDirection(fixedDirection)
#movingres_itk_float32.SetSize(fixedSize)

#check if it is now the same:
print("image direction: {}".format(movingres_itk_float32.GetDirection())) 
print("image origin: {}".format(movingres_itk_float32.GetOrigin()))
print("image size: {}".format(movingres_itk_float32.GetSize()))
print("image size: {}".format(movingres_itk_float32.GetSpacing()))
'''

dtype = torch.float32  # set the used data type
device = torch.device("cuda:0") # set the device for the computaion to GPU
#device = torch.device("cpu") # set the device for the computaion to CPU

fixed = al.create_tensor_image_from_itk_image(fixed, dtype=dtype, device=device)
moving = al.create_tensor_image_from_itk_image(movingres, dtype=dtype, device=device)
annotated = al.create_tensor_image_from_itk_image(annotatedres, dtype=dtype, device=device)

#moving = al.create_tensor_image_from_itk_image(movingres_itk_float32, dtype=dtype, device=device)
#movingres = al.create_tensor_image_from_itk_image(movingres, dtype=dtype, device=device)
#normalize:
fixed_image, moving_image = al.utils.normalize_images(fixed, moving)
fixed_image, annotated_image = al.utils.normalize_images(fixed, annotated)

#convert back to itk image
moving_itk=image_to_itk(moving_image)
fixed_itk=image_to_itk(fixed_image)
annotated_itk=image_to_itk(annotated_image)

print("MOVING IMAGE")
print("image spacing: {}".format(moving_itk.GetSpacing()))
print("image origin: {}".format(moving_itk.GetOrigin()))
print("image size: {}".format(moving_itk.GetSize()))
print("image direction: {}".format(moving_itk.GetDirection()))

print("FIXED IMAGE")
print("image spacing: {}".format(fixed_itk.GetSpacing()))
print("image origin: {}".format(fixed_itk.GetOrigin()))
print("image size: {}".format(fixed_itk.GetSize()))
print("image direction: {}".format(fixed_itk.GetDirection()))

print("ANNOTATED IMAGE")
print("image spacing: {}".format(annotated_itk.GetSpacing()))
print("image origin: {}".format(annotated_itk.GetOrigin()))
print("image size: {}".format(annotated_itk.GetSize()))
print("image direction: {}".format(annotated_itk.GetDirection()))

#sitk.WriteImage(annotated_itk, '/gdrive/My Drive/DWI_Images/normalized_annotationpatient13_itk.nii.gz')

def difference_image(image1, image2):

    dtype = image1.dtype
    device = image1.device

    image1 = image1.itk()
    image2 = image2.itk()

    # resample image2 if it does not occupy the same space as image1
    if not np.array_equal(image1.GetOrigin(),image2.GetOrigin()) or not np.array_equal(image1.GetSize(),image2.GetSize()) or not np.array_equal(image1.GetSpacing(),image2.GetSpacing()):
        image2 = resample(image2, downsample=0, reference=image1,  interp='linear')

    diff_image = sitk.Subtract(image1, image2)

    arr = sitk.GetArrayFromImage(diff_image)
    arr = np.transpose(arr)
    diff_image = al.Image(arr, arr.shape, diff_image.GetSpacing(), diff_image.GetOrigin())

    return diff_image

#diff_image = difference_image(fixed_image, moving_image)

#display_images(image_to_itk(diff_image), title='Difference image', window_max=1, window_min=-1)

'''
import torch
torch.cuda.empty_cache()

!pip install GPUtil

import torch
from GPUtil import showUtilization as gpu_usage
from numba import cuda

def free_gpu_cache():
    print("Initial GPU Usage")
    gpu_usage()                             

    torch.cuda.empty_cache()

    cuda.select_device(0)
    cuda.close()
    cuda.select_device(0)

    print("GPU Usage after emptying the cache")
    gpu_usage()

free_gpu_cache()     
'''

'''
#REGISTER ANNOTATED IMAGE ONTO PATIENT10 : AFFINE REGISTRATION
# create pairwise registration object
registration = al.PairwiseRegistration()

# choose the transformation model
#sigma = [5,5,5]  
#before:
#sigma = [5,5]
transformation = al.transformation.pairwise.AffineTransformation(moving_image, opt_cm=False) #try non-rigid
registration.set_transformation(transformation)

# choose the Mean Squared Error as image loss
image_loss = al.loss.pairwise.NCC(fixed_image, moving_image)

#regulariser = al.regulariser.displacement.DiffusionRegulariser(moving_image.spacing)
#regulariser.setweight(500)

# registration.set_regulariser_displacement([regulariser])

registration.set_image_loss([image_loss])

# choose the Adam optimizer to minimize the objective
optimizer = torch.optim.Adam(transformation.parameters(), lr=0.01, amsgrad=True)

registration.set_optimizer(optimizer)
registration.set_number_of_iterations(300)

# start the registration
registration.start()

# warp the moving image with the final transformation result
displacement = transformation.get_displacement()
warped_image = al.transformation.utils.warp_image(moving_image, displacement)
# put the same displacement on the annotated image -> moving image=annotated image 
warped_image_annotated= al.transformation.utils.warp_image(annotated_image, displacement)
'''

# create pairwise registration object
registration = al.PairwiseRegistration()

# choose the transformation model
transformation = al.transformation.pairwise.FlowTransformation(moving_image)
registration.set_transformation(transformation)

# choose the Normalized Cross-Correlation as image loss
image_loss = al.loss.pairwise.NCC(fixed_image, moving_image)
registration.set_image_loss([image_loss])

# choose Diffusion Regularization as a regularizer to control the amount of deformation
regularizer = al.regularizer.flow.DiffusionRegularizer(moving_image.spacing)
regularizer.set_weight(0.01)
registration.set_regularizer_flow([regularizer])

# choose the Adam optimizer to minimize the objective
optimizer = torch.optim.Adam(transformation.parameters(), lr=0.1, amsgrad=True)
registration.set_optimizer(optimizer)

# set the number of iterations for the registration
registration.set_number_of_iterations(500)

# start the registration
registration.start()

# warp the moving image with the final transformation result
displacement = transformation.get_displacement()
warped_image = al.transformation.utils.warp_image(moving_image, displacement)

# put the same displacement on the annotated image -> moving image=annotated image 
warped_image_annotated = al.transformation.utils.warp_image(annotated_image, displacement)

'''
diff_image_start = difference_image(fixed_image, moving_image)
diff_image_end = difference_image(fixed_image, warped_image)

display_images([image_to_itk(fixed_image), image_to_itk(moving_image), image_to_itk(warped_image)],
    title=['Fixed image', 'Moving image before', 'Moving image after'], window_max=1, window_min=0)


display_images([image_to_itk(diff_image_start), image_to_itk(diff_image_end)],
    title=['Difference image before', 'Difference image after'], window_max=1, window_min=-1)
'''

warped_image_itk=image_to_itk(warped_image) #convert airlab image to simpleitk #PET
warped_image_annotated_itk=image_to_itk(warped_image_annotated)

sitk.WriteImage(warped_image_itk, '/gdrive/My Drive/PET_Images/Registered_PET/0903_registered_PET_patient10.nii.gz')
sitk.WriteImage(warped_image_annotated_itk, '/gdrive/My Drive/DWI_Images/RegisteredAnnotationsforFusion/0903registered_annotation_patient10.nii.gz')#haben wir schon (0901registeredAnnotations)
sitk.WriteImage(fixed_itk, '/gdrive/My Drive/DWI_Images/RegisteredDWIsforFusion/0903registered_DWI_patient10.nii.gz') #stays always the same! #haben wir schon (0901registeredOriginals)

print("image spacing: {}".format(warped_image_itk.GetSpacing()))
print("image origin: {}".format(moving_itk.GetOrigin()))
print("image size: {}".format(moving_itk.GetSize()))

print("should be the same than:")

print("image spacing: {}".format(fixed_itk.GetSpacing()))
print("image origin: {}".format(fixed_itk.GetOrigin()))
print("image size: {}".format(fixed_itk.GetSize()))

print("should be the same than:")

print("image spacing: {}".format(annotated_itk.GetSpacing()))
print("image origin: {}".format(fixed_itk.GetOrigin()))
print("image size: {}".format(fixed_itk.GetSize()))

